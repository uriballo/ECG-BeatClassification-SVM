{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from biosppy.signals import ecg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_classes_map = {\n",
    "    'N': 'Normal beat',\n",
    "    'L': 'Left bundle branch block beat',\n",
    "    'R': 'Right bundle branch block beat',\n",
    "    'V': 'Premature ventricular contraction',\n",
    "    '/': 'Paced beat',\n",
    "    'f': 'Fusion of paced and normal beat',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove baseline wander using DWT\n",
    "def remove_baseline_wander(signal, wavelet=\"db4\", level=8):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    return pywt.waverec(coeffs, wavelet)\n",
    "\n",
    "# Function to smooth signal using Savitzky-Golay filter\n",
    "def smooth_signal(signal, window_length=11, polyorder=3):\n",
    "    return savgol_filter(signal, window_length, polyorder)\n",
    "\n",
    "# Function to segment the ECG signal around the R-peaks\n",
    "def segment_ecg_signal(ecg_signal, left_offset=100, right_offset=150):\n",
    "    segments = []\n",
    "    sampling_rate = 360\n",
    "    \n",
    "    out = ecg.ecg(signal=ecg_signal, sampling_rate=sampling_rate, show=False)\n",
    "    \n",
    "    r_peaks = out['rpeaks']\n",
    "\n",
    "    # Segment the signal around the R-peaks\n",
    "    for r_peak in r_peaks:\n",
    "        start = max(r_peak - left_offset, 0)  # ensure start is not negative\n",
    "        end = min(r_peak + right_offset, len(ecg_signal))  # ensure end does not go past the signal length\n",
    "        segment = ecg_signal[start:end]\n",
    "        if len(segment) == (left_offset + right_offset):  # only append if the segment is the correct length\n",
    "            segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Function to extract features using DWT\n",
    "def extract_dwt_features(segments, wavelet='db2', level=4):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "        # Only use the approximation coefficients at the given level\n",
    "        features.append(coeffs[0])\n",
    "    return features\n",
    "\n",
    "def parse_annotations(annotations):\n",
    "    annotation_pattern = re.compile(r'\\s*(\\d+:\\d+\\.\\d+)\\s+(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s*(\\(.*\\))?')\n",
    "    parsed_annotations = []\n",
    "    for line in annotations:\n",
    "        match = annotation_pattern.match(line)\n",
    "        if match:\n",
    "            time, sample_number, annotation_type, sub, chan, num, aux = match.groups()\n",
    "            # Map the annotation type to your classes of interest, or 'Other' if not found\n",
    "            annotation_type_mapped = annotation_type if annotation_type in annotation_classes_map else 'Other' \n",
    "            parsed_annotations.append((time, int(sample_number), annotation_type_mapped, int(sub), int(chan), int(num), aux))\n",
    "    return pd.DataFrame(parsed_annotations, columns=['Time', 'Sample #', 'Type', 'Sub', 'Chan', 'Num', 'Aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 20321, '/': 2166, 'V': 1985, 'Other': 1918, 'R': 1720, 'L': 993, 'f': 328})\n"
     ]
    }
   ],
   "source": [
    "train_patient_ids = ['100', '104', '108', '117', '201', '207', '212', '217', '222', '231', '101', '114', '123', '208', '213', '219', '223', '232', '102', '106', '119', '124', '203', '209', '214', '228', '233', '103', '107', '112', '116', '121', '200', '205', '210', '215', '221', '230', '234']\n",
    "\n",
    "# Initialize empty lists to hold the aggregated features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "beat_type_counter = Counter()\n",
    "\n",
    "for patient_id in train_patient_ids:\n",
    "    # Load the ECG data and annotations for each patient\n",
    "    with open(f'./datasets/{patient_id}annotations.txt', 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "        \n",
    "    ecg_data = pd.read_csv(f'./datasets/{patient_id}.csv')\n",
    "    annotations_df = parse_annotations(annotations)\n",
    "    \n",
    "    # Sampling rate and duration for 5 minutes\n",
    "    sampling_rate = 360  # samples per second for MIT-BIH\n",
    "    duration = 10 * 60  \n",
    "    num_samples = duration * sampling_rate\n",
    "\n",
    "    ecg_data.columns = ecg_data.columns.str.strip(\"'\")\n",
    "\n",
    "    start_sample = 0  \n",
    "    ecg_portion = ecg_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "    ecg_portion['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion['MLII'])\n",
    "    ecg_portion['ECG_smoothed'] = smooth_signal(ecg_portion['ECG_baseline_removed'])\n",
    "\n",
    "    # Filter annotations to only include those within the 5-minute window\n",
    "    annotations_portion = annotations_df[(annotations_df['Sample #'] >= start_sample) & \n",
    "                                        (annotations_df['Sample #'] < start_sample + num_samples)]\n",
    "    ecg_segments = segment_ecg_signal(ecg_portion['ECG_smoothed'])\n",
    "    ecg_features = extract_dwt_features(ecg_segments)\n",
    "\n",
    "    feature_matrix_patient = np.array(ecg_features)\n",
    "    labels_patient = annotations_portion['Type'].values[:len(ecg_features)]  # Ensuring labels align with the segments\n",
    "\n",
    "    # Append the features and labels to the aggregate lists\n",
    "    all_features.append(feature_matrix_patient)\n",
    "    all_labels.append(labels_patient)\n",
    "    beat_type_counter.update(labels_patient)\n",
    "\n",
    "# Combine all features and labels into single arrays\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(beat_type_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 850, 'R': 850, '/': 550, 'L': 500, 'V': 300, 'f': 150})\n"
     ]
    }
   ],
   "source": [
    "desired_counts = {\n",
    "    'N': 850,\n",
    "    'L': 500,\n",
    "    'R': 850,\n",
    "    'f': 150,\n",
    "    'V': 300,\n",
    "    '/': 550\n",
    "}\n",
    "\n",
    "balanced_features = []\n",
    "balanced_labels = []\n",
    "\n",
    "# For each beat type, balance according to the desired count\n",
    "for beat_type, count in desired_counts.items():\n",
    "    # Find the indices of the current beat type\n",
    "    indices = np.where(all_labels == beat_type)[0]\n",
    "\n",
    "    if beat_type_counter[beat_type] > count:\n",
    "        # Downsample if there are more than the desired count\n",
    "        chosen_indices = np.random.choice(indices, count, replace=False)\n",
    "    else:\n",
    "        # Upsample if there are fewer than the desired count\n",
    "        # Note: This is only advisable if you have a method to add variance to the data or if replicating data is acceptable\n",
    "        chosen_indices = np.random.choice(indices, count, replace=True)\n",
    "\n",
    "    # Append the balanced data\n",
    "    balanced_features.append(all_features[chosen_indices])\n",
    "    balanced_labels.append(all_labels[chosen_indices])\n",
    "\n",
    "# Combine all balanced data into single arrays\n",
    "balanced_features = np.vstack(balanced_features)\n",
    "balanced_labels = np.concatenate(balanced_labels)\n",
    "\n",
    "all_features = balanced_features\n",
    "all_labels = balanced_labels\n",
    "# Confirm the balancing\n",
    "print(Counter(balanced_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Accuracy for patient 105: 0.8533653846153846\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                      Normal beat       0.96      0.89      0.92       397\n",
      "                            Other       0.00      0.00      0.00         7\n",
      "Premature ventricular contraction       0.05      0.17      0.08        12\n",
      "\n",
      "                        micro avg       0.87      0.85      0.86       416\n",
      "                        macro avg       0.34      0.35      0.33       416\n",
      "                     weighted avg       0.91      0.85      0.88       416\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 109: 0.025522041763341066\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "    Left bundle branch block beat       1.00      0.02      0.04       422\n",
      "                            Other       0.00      0.00      0.00         3\n",
      "Premature ventricular contraction       0.01      0.50      0.02         6\n",
      "\n",
      "                        micro avg       0.03      0.03      0.03       431\n",
      "                        macro avg       0.34      0.17      0.02       431\n",
      "                     weighted avg       0.98      0.03      0.04       431\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 111: 0.0\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "Left bundle branch block beat       0.00      0.00      0.00     343.0\n",
      "                        Other       0.00      0.00      0.00       5.0\n",
      "\n",
      "                    micro avg       0.00      0.00      0.00     348.0\n",
      "                    macro avg       0.00      0.00      0.00     348.0\n",
      "                 weighted avg       0.00      0.00      0.00     348.0\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 113: 0.25951557093425603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.99      0.26      0.41       287\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.99      0.26      0.41       289\n",
      "   macro avg       0.49      0.13      0.21       289\n",
      "weighted avg       0.98      0.26      0.41       289\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 115: 0.9650793650793651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       1.00      0.97      0.98       314\n",
      "       Other       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       1.00      0.97      0.98       315\n",
      "   macro avg       0.50      0.48      0.49       315\n",
      "weighted avg       0.99      0.97      0.98       315\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 118: 0.016666666666666666\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                            Other       0.00      0.00      0.00        16\n",
      "   Right bundle branch block beat       0.86      0.02      0.03       341\n",
      "Premature ventricular contraction       0.00      0.00      0.00         3\n",
      "\n",
      "                        micro avg       0.86      0.02      0.03       360\n",
      "                        macro avg       0.29      0.01      0.01       360\n",
      "                     weighted avg       0.81      0.02      0.03       360\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 122: 0.6071428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       1.00      0.61      0.76       419\n",
      "       Other       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       1.00      0.61      0.75       420\n",
      "   macro avg       0.50      0.30      0.38       420\n",
      "weighted avg       0.99      0.61      0.75       420\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 202: 0.366412213740458\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                      Normal beat       0.99      0.36      0.53       257\n",
      "                            Other       0.00      0.00      0.00         1\n",
      "Premature ventricular contraction       0.02      0.75      0.03         4\n",
      "\n",
      "                         accuracy                           0.37       262\n",
      "                        macro avg       0.34      0.37      0.19       262\n",
      "                     weighted avg       0.97      0.37      0.52       262\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 220: 0.9943342776203966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.99      1.00      1.00       351\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       353\n",
      "   macro avg       0.50      0.50      0.50       353\n",
      "weighted avg       0.99      0.99      0.99       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_patient_ids = ['105', '109', '111', '113', '115', '118', '122', '202', '220']\n",
    "\n",
    "for test_patient_id in test_patient_ids:\n",
    "    with open(f'./datasets/{test_patient_id}annotations.txt', 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "    \n",
    "    ecg_test_data = pd.read_csv(f'./datasets/{test_patient_id}.csv')\n",
    "    annotations_test_df = parse_annotations(annotations)\n",
    "    ecg_test_data.columns = ecg_test_data.columns.str.strip(\"'\")\n",
    "\n",
    "    # Sampling rate and duration for 5 minutes\n",
    "    sampling_rate = 360  # samples per second for MIT-BIH\n",
    "    duration = 5 * 60  # 5 minutes in seconds\n",
    "    num_samples = duration * sampling_rate\n",
    "\n",
    "    start_sample = 0  \n",
    "    ecg_test_portion = ecg_test_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "    ecg_test_portion['ECG_baseline_removed'] = remove_baseline_wander(ecg_test_portion['MLII'])\n",
    "    ecg_test_portion['ECG_smoothed'] = smooth_signal(ecg_test_portion['ECG_baseline_removed'])\n",
    "\n",
    "    # Filter annotations to only include those within the 5-minute window\n",
    "    annotations_test_portion = annotations_test_df[(annotations_test_df['Sample #'] >= start_sample) & \n",
    "                                        (annotations_test_df['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "    ecg_test_segments = segment_ecg_signal(ecg_test_portion['ECG_smoothed'])\n",
    "    ecg_test_features = extract_dwt_features(ecg_test_segments)\n",
    "\n",
    "    feature_matrix_test = np.array(ecg_test_features)\n",
    "    labels_test_patient = annotations_test_portion['Type'].values[:len(ecg_test_features)]  # Ensuring labels align with the segments\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(all_features)\n",
    "    X_test_scaled = scaler.transform(feature_matrix_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='rbf', gamma='auto', class_weight='balanced')\n",
    "\n",
    "    svm_classifier.fit(X_train_scaled, all_labels)\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    y_pred = svm_classifier.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(labels_test_patient, y_pred)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f'Accuracy for patient {test_patient_id}: {accuracy}')\n",
    "\n",
    "    # Generate the classification report for patient 109's data\n",
    "    classification_rep_test = classification_report(labels_test_patient, y_pred, labels=np.unique(labels_test_patient), \n",
    "                                                target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels_test_patient)], \n",
    "                                                zero_division=0)\n",
    "\n",
    "    print(classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Positives (TP): [351   0]\n",
      "False Positives (FP): [2 0]\n",
      "False Negatives (FN): [0 2]\n",
      "True Negatives (TN): [  0 351]\n",
      "Sensitivity (TPR): [1. 0.]\n",
      "Precision (PPV): [0.99433428        nan]\n",
      "Accuracy (ACC): [0.99433428 0.99433428]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_9907/485243781.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    cm = confusion_matrix(labels_test_patient, y_pred, labels=np.unique(labels_test_patient))\n",
    "    print()\n",
    "\n",
    "    # Calculate additional metrics from the confusion matrix if needed\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP / (TP + FN)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP / (TP + FP)\n",
    "    # Overall accuracy for each class\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "    # Print additional metrics\n",
    "    print(f\"True Positives (TP): {TP}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(f\"True Negatives (TN): {TN}\")\n",
    "    print(f\"Sensitivity (TPR): {TPR}\")\n",
    "    print(f\"Precision (PPV): {PPV}\")\n",
    "    print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for patient ['105', '109', '111', '113', '115', '118', '122', '202', '220']: 0.9943342776203966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.99      1.00      1.00       351\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       353\n",
      "   macro avg       0.50      0.50      0.50       353\n",
      "weighted avg       0.99      0.99      0.99       353\n",
      "\n",
      "\n",
      "True Positives (TP): [351   0]\n",
      "False Positives (FP): [2 0]\n",
      "False Negatives (FN): [0 2]\n",
      "True Negatives (TN): [  0 351]\n",
      "Sensitivity (TPR): [1. 0.]\n",
      "Precision (PPV): [0.99433428        nan]\n",
      "Accuracy (ACC): [0.99433428 0.99433428]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_9907/2053860993.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(all_features)\n",
    "X_test_scaled = scaler.transform(feature_matrix_test)\n",
    "\n",
    "svm_classifier = SVC(kernel='rbf', gamma='auto')\n",
    "\n",
    "svm_classifier.fit(X_train_scaled, all_labels)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(labels_test_patient, y_pred)\n",
    "\n",
    "print(f'Accuracy for patient {test_patient_ids}: {accuracy}')\n",
    "\n",
    "# Generate the classification report for patient 109's data\n",
    "classification_rep_test = classification_report(labels_test_patient, y_pred, labels=np.unique(labels_test_patient), \n",
    "                                               target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels_test_patient)], \n",
    "                                               zero_division=0)\n",
    "\n",
    "print(classification_rep_test)\n",
    "\n",
    "cm = confusion_matrix(labels_test_patient, y_pred, labels=np.unique(labels_test_patient))\n",
    "print()\n",
    "\n",
    "# Calculate additional metrics from the confusion matrix if needed\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"Sensitivity (TPR): {TPR}\")\n",
    "print(f\"Precision (PPV): {PPV}\")\n",
    "print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Case Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsub\u001b[39m(left, right):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m annotations_portion111 \u001b[38;5;241m=\u001b[39m annotations_df111[(annotations_df111[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample #\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_sample) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     23\u001b[0m                                      (annotations_df111[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample #\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m start_sample \u001b[38;5;241m+\u001b[39m num_samples)]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Segmentation and feature extraction on the 5-minute portion\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m ecg_segments111 \u001b[38;5;241m=\u001b[39m \u001b[43msegment_ecg_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_portion111\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mECG_smoothed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations_portion111\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m ecg_features111 \u001b[38;5;241m=\u001b[39m extract_dwt_features(ecg_segments111)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Feature matrix and labels for the 5-minute portion\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 20\u001b[0m, in \u001b[0;36msegment_ecg_signal\u001b[0;34m(ecg_signal, left_offset, right_offset)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Segment the signal around the R-peaks\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r_peak \u001b[38;5;129;01min\u001b[39;00m r_peaks:\n\u001b[0;32m---> 20\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[43mr_peak\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_offset\u001b[49m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# ensure start is not negative\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(r_peak \u001b[38;5;241m+\u001b[39m right_offset, \u001b[38;5;28mlen\u001b[39m(ecg_signal))  \u001b[38;5;66;03m# ensure end does not go past the signal length\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     segment \u001b[38;5;241m=\u001b[39m ecg_signal[start:end]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:2102\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   2101\u001b[0m ):\n\u001b[0;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:273\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _standardize_out_kwarg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_dispatch_ufunc_to_dunder_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32mops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rsub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:7647\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7644\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7646\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 7647\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:7679\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7676\u001b[0m right \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(right)\n\u001b[1;32m   7677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   7678\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[0;32m-> 7679\u001b[0m     bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[38;5;241m=\u001b[39mbm\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   7682\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(f):\n\u001b[0;32m--> 352\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:229\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    223\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    224\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:184\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    181\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 184\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    187\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsub\u001b[39m(left, right):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('./datasets/111annotations.txt', 'r') as file:\n",
    "    annotations = file.readlines()\n",
    "ecg_data111 = pd.read_csv('./datasets/111.csv')\n",
    "annotations_df111 = parse_annotations(annotations)\n",
    "\n",
    "# Correct the column names by removing extra quotation marks\n",
    "ecg_data111.columns = ecg_data111.columns.str.strip(\"'\")\n",
    "\n",
    "# Sampling rate and duration for 5 minutes\n",
    "sampling_rate = 360  # samples per second for MIT-BIH\n",
    "duration = 5 * 60  # 5 minutes in seconds\n",
    "num_samples = duration * sampling_rate\n",
    "\n",
    "# Extract a 5-minute portion of the ECG data\n",
    "start_sample = 0  # You can adjust this as needed\n",
    "ecg_portion111 = ecg_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion111['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion111['MLII'])\n",
    "ecg_portion111['ECG_smoothed'] = smooth_signal(ecg_portion111['ECG_baseline_removed'])\n",
    "\n",
    "# Filter annotations to only include those within the 5-minute window\n",
    "annotations_portion111 = annotations_df111[(annotations_df111['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df111['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments111 = segment_ecg_signal(ecg_portion111['ECG_smoothed'], annotations_portion111)\n",
    "ecg_features111 = extract_dwt_features(ecg_segments111)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix111 = np.array(ecg_features111)\n",
    "labels111 = annotations_portion111['Type'].values[:len(ecg_features111)]  # Ensuring labels align with the segments\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L        424\n",
      "V          6\n",
      "Other      3\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/109annotations.txt', 'r') as file:\n",
    "    annotations_109 = file.readlines()\n",
    "ecg_data_109 = pd.read_csv('datasets/109.csv')\n",
    "annotations_df_109 = parse_annotations(annotations_109)\n",
    "\n",
    "ecg_data_109.columns = ecg_data_109.columns.str.strip(\"'\")\n",
    "\n",
    "ecg_portion109 = ecg_data_109.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion109['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion109['MLII'])\n",
    "ecg_portion109['ECG_smoothed'] = smooth_signal(ecg_portion109['ECG_baseline_removed'])\n",
    "\n",
    "annotations_portion109 = annotations_df_109[(annotations_df_109['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df_109['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments109 = segment_ecg_signal(ecg_portion109['ECG_smoothed'], annotations_portion109)\n",
    "ecg_features109 = extract_dwt_features(ecg_segments109)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix109 = np.array(ecg_features109)\n",
    "labels109 = annotations_portion109['Type'].values[:len(ecg_features109)]  # Ensuring labels align with the segments\n",
    "\n",
    "print(pd.Series(labels109).value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for patient 109: 0.9792147806004619\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "    Left bundle branch block beat       0.98      1.00      0.99       424\n",
      "                            Other       0.00      0.00      0.00         3\n",
      "Premature ventricular contraction       0.00      0.00      0.00         6\n",
      "\n",
      "                         accuracy                           0.98       433\n",
      "                        macro avg       0.33      0.33      0.33       433\n",
      "                     weighted avg       0.96      0.98      0.97       433\n",
      "\n",
      "\n",
      "True Positives (TP): [424   0   0]\n",
      "False Positives (FP): [9 0 0]\n",
      "False Negatives (FN): [0 3 6]\n",
      "True Negatives (TN): [  0 430 427]\n",
      "Sensitivity (TPR): [1. 0. 0.]\n",
      "Precision (PPV): [0.97921478        nan        nan]\n",
      "Accuracy (ACC): [0.97921478 0.99307159 0.98614319]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_8122/2035090956.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(feature_matrix111)\n",
    "X_test_scaled = scaler.transform(feature_matrix109)\n",
    "\n",
    "# SVM training with patient 111's data\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train_scaled, labels111)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(labels109, y_pred)\n",
    "\n",
    "# Generate the classification report for patient 109's data\n",
    "classification_rep_109 = classification_report(labels109, y_pred, labels=np.unique(labels109), target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels109)], zero_division=0)\n",
    "\n",
    "print(f'Accuracy for patient 109: {accuracy}')\n",
    "print(classification_rep_109)\n",
    "\n",
    "cm = confusion_matrix(labels109, y_pred, labels=np.unique(labels109))\n",
    "print()\n",
    "\n",
    "# Calculate additional metrics from the confusion matrix if needed\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"Sensitivity (TPR): {TPR}\")\n",
    "print(f\"Precision (PPV): {PPV}\")\n",
    "print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_classes_map = {\n",
    "    'N': 'Normal beat',\n",
    "    'L': 'Left bundle branch block beat',\n",
    "    'R': 'Right bundle branch block beat',\n",
    "    'V': 'Premature ventricular contraction',\n",
    "    '/': 'Paced beat',\n",
    "    'f': 'Fusion of paced and normal beat',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove baseline wander using DWT\n",
    "def remove_baseline_wander(signal, wavelet=\"db4\", level=8):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    return pywt.waverec(coeffs, wavelet)\n",
    "\n",
    "# Function to smooth signal using Savitzky-Golay filter\n",
    "def smooth_signal(signal, window_length=11, polyorder=3):\n",
    "    return savgol_filter(signal, window_length, polyorder)\n",
    "\n",
    "# Function to segment the ECG signal around the R-peaks\n",
    "def segment_ecg_signal(ecg_signal, annotations_df, r_peak_offset=150, segment_length=251):\n",
    "    segments = []\n",
    "    for _, row in annotations_df.iterrows():\n",
    "        r_peak = row['Sample #']\n",
    "        start = r_peak - r_peak_offset\n",
    "        end = start + segment_length\n",
    "        if start >= 0 and end <= len(ecg_signal):\n",
    "            segment = ecg_signal[start:end]\n",
    "            segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Function to extract features using DWT\n",
    "def extract_dwt_features(segments, wavelet='db4', level=4):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "        features.append(np.concatenate(coeffs))\n",
    "    return features\n",
    "\n",
    "# Parse annotations\n",
    "def pars3e_annotations(annotations):\n",
    "    annotation_pattern = re.compile(r'\\s*(\\d+:\\d+\\.\\d+)\\s+(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s*(\\(.*\\))?')\n",
    "    parsed_annotations = []\n",
    "    for line in annotations:\n",
    "        match = annotation_pattern.match(line)\n",
    "        if match:\n",
    "            time, sample_number, annotation_type, sub, chan, num, aux = match.groups()\n",
    "            parsed_annotations.append((time, int(sample_number), annotation_type, int(sub), int(chan), int(num), aux))\n",
    "    return pd.DataFrame(parsed_annotations, columns=['Time', 'Sample #', 'Type', 'Sub', 'Chan', 'Num', 'Aux'])\n",
    "\n",
    "def parse_annotations(annotations):\n",
    "    annotation_pattern = re.compile(r'\\s*(\\d+:\\d+\\.\\d+)\\s+(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s*(\\(.*\\))?')\n",
    "    parsed_annotations = []\n",
    "    for line in annotations:\n",
    "        match = annotation_pattern.match(line)\n",
    "        if match:\n",
    "            time, sample_number, annotation_type, sub, chan, num, aux = match.groups()\n",
    "            # Map the annotation type to your classes of interest, or 'Other' if not found\n",
    "            annotation_type_mapped = annotation_type if annotation_type in annotation_classes_map else 'Other' #annotation_classes_map.get(annotation_type, 'Other')\n",
    "            parsed_annotations.append((time, int(sample_number), annotation_type_mapped, int(sub), int(chan), int(num), aux))\n",
    "    return pd.DataFrame(parsed_annotations, columns=['Time', 'Sample #', 'Type', 'Sub', 'Chan', 'Num', 'Aux'])\n",
    "\n",
    "# Function to only rename labels without a corresponding key in annotation_map\n",
    "def rename_unmapped_labels(labels, annotation_map):\n",
    "    # Check if the label is in annotation_map, if not replace it with 'Other'\n",
    "    return np.array([label if label in annotation_classes_map else 'Other' for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9176007270524084\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                       Paced beat       0.89      0.95      0.92       804\n",
      "    Left bundle branch block beat       0.99      0.98      0.98       385\n",
      "                      Normal beat       0.92      0.99      0.95      1866\n",
      "                            Other       0.00      0.00      0.00        55\n",
      "Premature ventricular contraction       0.84      0.36      0.51       102\n",
      "  Fusion of paced and normal beat       0.38      0.07      0.11        89\n",
      "\n",
      "                         accuracy                           0.92      3301\n",
      "                        macro avg       0.67      0.56      0.58      3301\n",
      "                     weighted avg       0.89      0.92      0.90      3301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "patient_ids = ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109']\n",
    "\n",
    "# Initialize empty lists to hold the aggregated features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    # Load the ECG data and annotations for each patient\n",
    "    ecg_data = pd.read_csv(f'./datasets/{patient_id}.csv')\n",
    "    \n",
    "    with open(f'./datasets/{patient_id}annotations.txt', 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "\n",
    "    annotations_df = parse_annotations(annotations)\n",
    "    ecg_data.columns = ecg_data.columns.str.strip(\"'\")  # Adjust as needed\n",
    "    ecg_data['ECG_baseline_removed'] = remove_baseline_wander(ecg_data['MLII'])  # Adjust the column name as needed\n",
    "    ecg_data['ECG_smoothed'] = smooth_signal(ecg_data['ECG_baseline_removed'])\n",
    "    ecg_segments = segment_ecg_signal(ecg_data['ECG_smoothed'], annotations_df)\n",
    "    ecg_features = extract_dwt_features(ecg_segments)\n",
    "\n",
    "    # Prepare the labels\n",
    "    feature_matrix = np.array(ecg_features)\n",
    "    labels = rename_unmapped_labels(annotations_df['Type'].values, annotation_classes_map)\n",
    "\n",
    "    # Ensure that the number of labels matches the number of feature vectors\n",
    "    min_length = min(len(labels), len(feature_matrix))\n",
    "    feature_matrix = feature_matrix[:min_length]\n",
    "    labels = labels[:min_length]\n",
    "\n",
    "    # Append the features and labels to the aggregate lists\n",
    "    all_features.append(feature_matrix)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Combine all features and labels into single arrays\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM training\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate the classification report\n",
    "unique_labels = np.unique(np.concatenate((y_test, y_pred)))  # Unique labels in y_test and y_pred\n",
    "target_names = [annotation_classes_map.get(label, 'Other') for label in unique_labels]  # Corresponding target names\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred, labels=unique_labels, target_names=target_names)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L        347\n",
      "Other      5\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('./datasets/111annotations.txt', 'r') as file:\n",
    "    annotations = file.readlines()\n",
    "ecg_data = pd.read_csv('./datasets/111.csv')\n",
    "annotations_df = parse_annotations(annotations)\n",
    "\n",
    "# Correct the column names by removing extra quotation marks\n",
    "ecg_data.columns = ecg_data.columns.str.strip(\"'\")\n",
    "\n",
    "# Sampling rate and duration for 5 minutes\n",
    "sampling_rate = 360  # samples per second for MIT-BIH\n",
    "duration = 5 * 60  # 5 minutes in seconds\n",
    "num_samples = duration * sampling_rate\n",
    "\n",
    "# Extract a 5-minute portion of the ECG data\n",
    "start_sample = 0  # You can adjust this as needed\n",
    "ecg_portion = ecg_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion['MLII'])\n",
    "ecg_portion['ECG_smoothed'] = smooth_signal(ecg_portion['ECG_baseline_removed'])\n",
    "\n",
    "# Filter annotations to only include those within the 5-minute window\n",
    "annotations_portion = annotations_df[(annotations_df['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments = segment_ecg_signal(ecg_portion['ECG_smoothed'], annotations_portion)\n",
    "ecg_features = extract_dwt_features(ecg_segments)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix = np.array(ecg_features)\n",
    "labels = annotations_portion['Type'].values[:len(ecg_features)]  # Ensuring labels align with the segments\n",
    "print(pd.Series(labels).value_counts())\n",
    "#labels = rename_unmapped_labels(labels, annotation_classes_map)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L        422\n",
      "V          6\n",
      "Other      3\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/109annotations.txt', 'r') as file:\n",
    "    annotations_109 = file.readlines()\n",
    "ecg_data_109 = pd.read_csv('datasets/109.csv')\n",
    "annotations_df_109 = parse_annotations(annotations_109)\n",
    "\n",
    "ecg_data_109.columns = ecg_data_109.columns.str.strip(\"'\")\n",
    "\n",
    "ecg_portion109 = ecg_data_109.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion109['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion109['MLII'])\n",
    "ecg_portion109['ECG_smoothed'] = smooth_signal(ecg_portion109['ECG_baseline_removed'])\n",
    "\n",
    "annotations_portion109 = annotations_df_109[(annotations_df_109['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df_109['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments109 = segment_ecg_signal(ecg_portion109['ECG_smoothed'], annotations_portion109)\n",
    "ecg_features109 = extract_dwt_features(ecg_segments109)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix109 = np.array(ecg_features109)\n",
    "labels109 = annotations_portion109['Type'].values[:len(ecg_features109)]  # Ensuring labels align with the segments\n",
    "#labels109 = rename_unmapped_labels(labels109, annotation_classes_map)\n",
    "\n",
    "print(pd.Series(labels109).value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for patient 109: 0.9791183294663574\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "    Left bundle branch block beat       0.98      1.00      0.99       422\n",
      "                            Other       0.00      0.00      0.00         3\n",
      "Premature ventricular contraction       0.00      0.00      0.00         6\n",
      "\n",
      "                         accuracy                           0.98       431\n",
      "                        macro avg       0.33      0.33      0.33       431\n",
      "                     weighted avg       0.96      0.98      0.97       431\n",
      "\n",
      "\n",
      "True Positives (TP): [422   0]\n",
      "False Positives (FP): [3 0]\n",
      "False Negatives (FN): [0 3]\n",
      "True Negatives (TN): [  0 422]\n",
      "Sensitivity (TPR): [1. 0.]\n",
      "Precision (PPV): [0.99294118        nan]\n",
      "Accuracy (ACC): [0.99294118 0.99294118]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_1510/3558542549.py:30: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(feature_matrix)\n",
    "X_test_scaled = scaler.transform(feature_matrix109)\n",
    "\n",
    "# SVM training with patient 111's data\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train_scaled, labels)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(labels109, y_pred)\n",
    "\n",
    "# Generate the classification report for patient 109's data\n",
    "classification_rep_109 = classification_report(labels109, y_pred, labels=np.unique(labels109), target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels109)], zero_division=0)\n",
    "\n",
    "print(f'Accuracy for patient 109: {accuracy}')\n",
    "print(classification_rep_109)\n",
    "\n",
    "cm = confusion_matrix(labels109, y_pred, labels=unique_labels)\n",
    "print()\n",
    "\n",
    "# Calculate additional metrics from the confusion matrix if needed\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"Sensitivity (TPR): {TPR}\")\n",
    "print(f\"Precision (PPV): {PPV}\")\n",
    "print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from biosppy.signals import ecg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_classes_map = {\n",
    "    'N': 'Normal beat',\n",
    "    'L': 'Left bundle branch block beat',\n",
    "    'R': 'Right bundle branch block beat',\n",
    "    'V': 'Premature ventricular contraction',\n",
    "    '/': 'Paced beat',\n",
    "    'f': 'Fusion of paced and normal beat',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove baseline wander using DWT\n",
    "def remove_baseline_wander(signal, wavelet=\"db4\", level=8):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    coeffs[-1] = np.zeros_like(coeffs[-1])\n",
    "    return pywt.waverec(coeffs, wavelet)\n",
    "\n",
    "# Function to smooth signal using Savitzky-Golay filter\n",
    "def smooth_signal(signal, window_length=11, polyorder=3):\n",
    "    return savgol_filter(signal, window_length, polyorder)\n",
    "\n",
    "# Function to segment the ECG signal around the R-peaks\n",
    "def segment_ecg_signal(ecg_signal, annotations_df, r_peak_offset=100, segment_length=251):\n",
    "    segments = []\n",
    "    for _, row in annotations_df.iterrows():\n",
    "        r_peak = row['Sample #']\n",
    "        start = max(r_peak - r_peak_offset, 0)  # ensure start is not negative\n",
    "        end = min(start + segment_length, len(ecg_signal))  # ensure end does not go past the signal length\n",
    "        segment = ecg_signal[start:end]\n",
    "        if len(segment) == segment_length:  # only append if the segment is the correct length\n",
    "            segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Function to extract features using DWT\n",
    "def extract_dwt_features(segments, wavelet='db2', level=4):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "        # Only use the approximation coefficients at the given level\n",
    "        features.append(coeffs[0])\n",
    "    return features\n",
    "\n",
    "def parse_annotations(annotations):\n",
    "    annotation_pattern = re.compile(r'\\s*(\\d+:\\d+\\.\\d+)\\s+(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s*(\\(.*\\))?')\n",
    "    parsed_annotations = []\n",
    "    for line in annotations:\n",
    "        match = annotation_pattern.match(line)\n",
    "        if match:\n",
    "            time, sample_number, annotation_type, sub, chan, num, aux = match.groups()\n",
    "            # Map the annotation type to your classes of interest, or 'Other' if not found\n",
    "            annotation_type_mapped = annotation_type if annotation_type in annotation_classes_map else 'Other' \n",
    "            parsed_annotations.append((time, int(sample_number), annotation_type_mapped, int(sub), int(chan), int(num), aux))\n",
    "    return pd.DataFrame(parsed_annotations, columns=['Time', 'Sample #', 'Type', 'Sub', 'Chan', 'Num', 'Aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 21084, '/': 2248, 'V': 2223, 'Other': 2090, 'R': 1775, 'L': 1138, 'f': 354})\n"
     ]
    }
   ],
   "source": [
    "train_patient_ids = ['100', '104', '108', '117', '201', '207', '212', '217', '222', '231', '101', '114', '123', '208', '213', '219', '223', '232', '102', '106', '119', '124', '203', '209', '214', '228', '233', '103', '107', '112', '116', '121', '200', '205', '210', '215', '221', '230', '234']\n",
    "\n",
    "# Initialize empty lists to hold the aggregated features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "beat_type_counter = Counter()\n",
    "\n",
    "for patient_id in train_patient_ids:\n",
    "    # Load the ECG data and annotations for each patient\n",
    "    with open(f'./datasets/{patient_id}annotations.txt', 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "        \n",
    "    ecg_data = pd.read_csv(f'./datasets/{patient_id}.csv')\n",
    "    annotations_df = parse_annotations(annotations)\n",
    "    \n",
    "    # Sampling rate and duration for 5 minutes\n",
    "    sampling_rate = 360  # samples per second for MIT-BIH\n",
    "    duration = 10 * 60  \n",
    "    num_samples = duration * sampling_rate\n",
    "\n",
    "    ecg_data.columns = ecg_data.columns.str.strip(\"'\")\n",
    "\n",
    "    start_sample = 0  \n",
    "    ecg_portion = ecg_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "    ecg_portion['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion['MLII'])\n",
    "    ecg_portion['ECG_smoothed'] = smooth_signal(ecg_portion['ECG_baseline_removed'])\n",
    "\n",
    "    # Filter annotations to only include those within the 5-minute window\n",
    "    annotations_portion = annotations_df[(annotations_df['Sample #'] >= start_sample) & \n",
    "                                        (annotations_df['Sample #'] < start_sample + num_samples)]\n",
    "    ecg_segments = segment_ecg_signal(ecg_portion['ECG_smoothed'], annotations_portion)\n",
    "    ecg_features = extract_dwt_features(ecg_segments)\n",
    "\n",
    "    feature_matrix_patient = np.array(ecg_features)\n",
    "    labels_patient = annotations_portion['Type'].values[:len(ecg_features)]  # Ensuring labels align with the segments\n",
    "\n",
    "    # Append the features and labels to the aggregate lists\n",
    "    all_features.append(feature_matrix_patient)\n",
    "    all_labels.append(labels_patient)\n",
    "    beat_type_counter.update(labels_patient)\n",
    "\n",
    "# Combine all features and labels into single arrays\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(beat_type_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 850, 'R': 850, '/': 550, 'L': 500, 'V': 300, 'f': 150})\n"
     ]
    }
   ],
   "source": [
    "desired_counts = {\n",
    "    'N': 850,\n",
    "    'L': 500,\n",
    "    'R': 850,\n",
    "    'f': 150,\n",
    "    'V': 300,\n",
    "    '/': 550\n",
    "}\n",
    "\n",
    "balanced_features = []\n",
    "balanced_labels = []\n",
    "\n",
    "# For each beat type, balance according to the desired count\n",
    "for beat_type, count in desired_counts.items():\n",
    "    # Find the indices of the current beat type\n",
    "    indices = np.where(all_labels == beat_type)[0]\n",
    "\n",
    "    if beat_type_counter[beat_type] > count:\n",
    "        # Downsample if there are more than the desired count\n",
    "        chosen_indices = np.random.choice(indices, count, replace=False)\n",
    "    else:\n",
    "        # Upsample if there are fewer than the desired count\n",
    "        # Note: This is only advisable if you have a method to add variance to the data or if replicating data is acceptable\n",
    "        chosen_indices = np.random.choice(indices, count, replace=True)\n",
    "\n",
    "    # Append the balanced data\n",
    "    balanced_features.append(all_features[chosen_indices])\n",
    "    balanced_labels.append(all_labels[chosen_indices])\n",
    "\n",
    "# Combine all balanced data into single arrays\n",
    "balanced_features = np.vstack(balanced_features)\n",
    "balanced_labels = np.concatenate(balanced_labels)\n",
    "\n",
    "all_features = balanced_features\n",
    "all_labels = balanced_labels\n",
    "# Confirm the balancing\n",
    "print(Counter(balanced_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Accuracy for patient 105: 0.9364705882352942\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                      Normal beat       0.97      0.98      0.97       404\n",
      "                            Other       0.00      0.00      0.00         9\n",
      "Premature ventricular contraction       0.25      0.17      0.20        12\n",
      "\n",
      "                        micro avg       0.95      0.94      0.95       425\n",
      "                        macro avg       0.41      0.38      0.39       425\n",
      "                     weighted avg       0.93      0.94      0.93       425\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 109: 0.006928406466512702\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "    Left bundle branch block beat       0.00      0.00      0.00       424\n",
      "                            Other       0.00      0.00      0.00         3\n",
      "Premature ventricular contraction       0.02      0.50      0.03         6\n",
      "\n",
      "                        micro avg       0.02      0.01      0.01       433\n",
      "                        macro avg       0.01      0.17      0.01       433\n",
      "                     weighted avg       0.00      0.01      0.00       433\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 111: 0.0\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "Left bundle branch block beat       0.00      0.00      0.00     348.0\n",
      "                        Other       0.00      0.00      0.00       5.0\n",
      "\n",
      "                    micro avg       0.00      0.00      0.00     353.0\n",
      "                    macro avg       0.00      0.00      0.00     353.0\n",
      "                 weighted avg       0.00      0.00      0.00     353.0\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 113: 0.3931034482758621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.98      0.40      0.56       288\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.98      0.39      0.56       290\n",
      "   macro avg       0.49      0.20      0.28       290\n",
      "weighted avg       0.98      0.39      0.56       290\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 115: 0.9968354430379747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       1.00      1.00      1.00       315\n",
      "       Other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00       316\n",
      "   macro avg       0.50      0.50      0.50       316\n",
      "weighted avg       0.99      1.00      1.00       316\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 118: 0.7683923705722071\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                            Other       0.00      0.00      0.00        16\n",
      "   Right bundle branch block beat       0.97      0.80      0.88       348\n",
      "Premature ventricular contraction       0.60      1.00      0.75         3\n",
      "\n",
      "                        micro avg       0.96      0.77      0.85       367\n",
      "                        macro avg       0.52      0.60      0.54       367\n",
      "                     weighted avg       0.92      0.77      0.84       367\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 122: 0.981042654028436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       1.00      0.98      0.99       421\n",
      "       Other       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       1.00      0.98      0.99       422\n",
      "   macro avg       0.50      0.49      0.50       422\n",
      "weighted avg       1.00      0.98      0.99       422\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 202: 0.9962406015037594\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                      Normal beat       1.00      1.00      1.00       261\n",
      "                            Other       0.00      0.00      0.00         1\n",
      "Premature ventricular contraction       1.00      1.00      1.00         4\n",
      "\n",
      "                         accuracy                           1.00       266\n",
      "                        macro avg       0.67      0.67      0.67       266\n",
      "                     weighted avg       0.99      1.00      0.99       266\n",
      "\n",
      "---------------------------------------------------\n",
      "Accuracy for patient 220: 0.9943661971830986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.99      1.00      1.00       353\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       355\n",
      "   macro avg       0.50      0.50      0.50       355\n",
      "weighted avg       0.99      0.99      0.99       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_patient_ids = ['105', '109', '111', '113', '115', '118', '122', '202', '220']\n",
    "\n",
    "for test_patient_id in test_patient_ids:\n",
    "    with open(f'./datasets/{test_patient_id}annotations.txt', 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "    \n",
    "    ecg_test_data = pd.read_csv(f'./datasets/{test_patient_id}.csv')\n",
    "    annotations_test_df = parse_annotations(annotations)\n",
    "    ecg_test_data.columns = ecg_test_data.columns.str.strip(\"'\")\n",
    "\n",
    "    # Sampling rate and duration for 5 minutes\n",
    "    sampling_rate = 360  # samples per second for MIT-BIH\n",
    "    duration = 5 * 60  # 5 minutes in seconds\n",
    "    num_samples = duration * sampling_rate\n",
    "\n",
    "    start_sample = 0  \n",
    "    ecg_test_portion = ecg_test_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "    ecg_test_portion['ECG_baseline_removed'] = remove_baseline_wander(ecg_test_portion['MLII'])\n",
    "    ecg_test_portion['ECG_smoothed'] = smooth_signal(ecg_test_portion['ECG_baseline_removed'])\n",
    "\n",
    "    # Filter annotations to only include those within the 5-minute window\n",
    "    annotations_test_portion = annotations_test_df[(annotations_test_df['Sample #'] >= start_sample) & \n",
    "                                        (annotations_test_df['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "    ecg_test_segments = segment_ecg_signal(ecg_test_portion['ECG_smoothed'], annotations_test_portion)\n",
    "    ecg_test_features = extract_dwt_features(ecg_test_segments)\n",
    "\n",
    "    feature_matrix_test = np.array(ecg_test_features)\n",
    "    labels_test_patient = annotations_test_portion['Type'].values[:len(ecg_test_features)]  # Ensuring labels align with the segments\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(all_features)\n",
    "    X_test_scaled = scaler.transform(feature_matrix_test)\n",
    "\n",
    "    svm_classifier = SVC(kernel='rbf', gamma='auto', class_weight='balanced')\n",
    "\n",
    "    svm_classifier.fit(X_train_scaled, all_labels)\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    y_pred = svm_classifier.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(labels_test_patient, y_pred)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f'Accuracy for patient {test_patient_id}: {accuracy}')\n",
    "\n",
    "    # Generate the classification report for patient 109's data\n",
    "    classification_rep_test = classification_report(labels_test_patient, y_pred, labels=np.unique(labels_test_patient), \n",
    "                                                target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels_test_patient)], \n",
    "                                                zero_division=0)\n",
    "\n",
    "    print(classification_rep_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Positives (TP): [353   0]\n",
      "False Positives (FP): [2 0]\n",
      "False Negatives (FN): [0 2]\n",
      "True Negatives (TN): [  0 353]\n",
      "Sensitivity (TPR): [1. 0.]\n",
      "Precision (PPV): [0.9943662       nan]\n",
      "Accuracy (ACC): [0.9943662 0.9943662]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_10050/485243781.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    cm = confusion_matrix(labels_test_patient, y_pred, labels=np.unique(labels_test_patient))\n",
    "    print()\n",
    "\n",
    "    # Calculate additional metrics from the confusion matrix if needed\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP / (TP + FN)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP / (TP + FP)\n",
    "    # Overall accuracy for each class\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "    # Print additional metrics\n",
    "    print(f\"True Positives (TP): {TP}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(f\"True Negatives (TN): {TN}\")\n",
    "    print(f\"Sensitivity (TPR): {TPR}\")\n",
    "    print(f\"Precision (PPV): {PPV}\")\n",
    "    print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for patient ['105', '109', '111', '113', '115', '118', '122', '202', '220']: 0.9943661971830986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Normal beat       0.99      1.00      1.00       353\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       355\n",
      "   macro avg       0.50      0.50      0.50       355\n",
      "weighted avg       0.99      0.99      0.99       355\n",
      "\n",
      "\n",
      "True Positives (TP): [353   0]\n",
      "False Positives (FP): [2 0]\n",
      "False Negatives (FN): [0 2]\n",
      "True Negatives (TN): [  0 353]\n",
      "Sensitivity (TPR): [1. 0.]\n",
      "Precision (PPV): [0.9943662       nan]\n",
      "Accuracy (ACC): [0.9943662 0.9943662]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_10050/2053860993.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(all_features)\n",
    "X_test_scaled = scaler.transform(feature_matrix_test)\n",
    "\n",
    "svm_classifier = SVC(kernel='rbf', gamma='auto')\n",
    "\n",
    "svm_classifier.fit(X_train_scaled, all_labels)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(labels_test_patient, y_pred)\n",
    "\n",
    "print(f'Accuracy for patient {test_patient_ids}: {accuracy}')\n",
    "\n",
    "# Generate the classification report for patient 109's data\n",
    "classification_rep_test = classification_report(labels_test_patient, y_pred, labels=np.unique(labels_test_patient), \n",
    "                                               target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels_test_patient)], \n",
    "                                               zero_division=0)\n",
    "\n",
    "print(classification_rep_test)\n",
    "\n",
    "cm = confusion_matrix(labels_test_patient, y_pred, labels=np.unique(labels_test_patient))\n",
    "print()\n",
    "\n",
    "# Calculate additional metrics from the confusion matrix if needed\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"Sensitivity (TPR): {TPR}\")\n",
    "print(f\"Precision (PPV): {PPV}\")\n",
    "print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Case Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('./datasets/111annotations.txt', 'r') as file:\n",
    "    annotations = file.readlines()\n",
    "ecg_data111 = pd.read_csv('./datasets/111.csv')\n",
    "annotations_df111 = parse_annotations(annotations)\n",
    "\n",
    "# Correct the column names by removing extra quotation marks\n",
    "ecg_data111.columns = ecg_data111.columns.str.strip(\"'\")\n",
    "\n",
    "# Sampling rate and duration for 5 minutes\n",
    "sampling_rate = 360  # samples per second for MIT-BIH\n",
    "duration = 5 * 60  # 5 minutes in seconds\n",
    "num_samples = duration * sampling_rate\n",
    "\n",
    "# Extract a 5-minute portion of the ECG data\n",
    "start_sample = 0  # You can adjust this as needed\n",
    "ecg_portion111 = ecg_data.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion111['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion111['MLII'])\n",
    "ecg_portion111['ECG_smoothed'] = smooth_signal(ecg_portion111['ECG_baseline_removed'])\n",
    "\n",
    "# Filter annotations to only include those within the 5-minute window\n",
    "annotations_portion111 = annotations_df111[(annotations_df111['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df111['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments111 = segment_ecg_signal(ecg_portion111['ECG_smoothed'], annotations_portion111)\n",
    "ecg_features111 = extract_dwt_features(ecg_segments111)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix111 = np.array(ecg_features111)\n",
    "labels111 = annotations_portion111['Type'].values[:len(ecg_features111)]  # Ensuring labels align with the segments\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L        424\n",
      "V          6\n",
      "Other      3\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/109annotations.txt', 'r') as file:\n",
    "    annotations_109 = file.readlines()\n",
    "ecg_data_109 = pd.read_csv('datasets/109.csv')\n",
    "annotations_df_109 = parse_annotations(annotations_109)\n",
    "\n",
    "ecg_data_109.columns = ecg_data_109.columns.str.strip(\"'\")\n",
    "\n",
    "ecg_portion109 = ecg_data_109.iloc[start_sample:start_sample + num_samples].copy()\n",
    "ecg_portion109['ECG_baseline_removed'] = remove_baseline_wander(ecg_portion109['MLII'])\n",
    "ecg_portion109['ECG_smoothed'] = smooth_signal(ecg_portion109['ECG_baseline_removed'])\n",
    "\n",
    "annotations_portion109 = annotations_df_109[(annotations_df_109['Sample #'] >= start_sample) & \n",
    "                                     (annotations_df_109['Sample #'] < start_sample + num_samples)]\n",
    "\n",
    "# Segmentation and feature extraction on the 5-minute portion\n",
    "ecg_segments109 = segment_ecg_signal(ecg_portion109['ECG_smoothed'], annotations_portion109)\n",
    "ecg_features109 = extract_dwt_features(ecg_segments109)\n",
    "\n",
    "# Feature matrix and labels for the 5-minute portion\n",
    "feature_matrix109 = np.array(ecg_features109)\n",
    "labels109 = annotations_portion109['Type'].values[:len(ecg_features109)]  # Ensuring labels align with the segments\n",
    "\n",
    "print(pd.Series(labels109).value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for patient 109: 0.9792147806004619\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "    Left bundle branch block beat       0.98      1.00      0.99       424\n",
      "                            Other       0.00      0.00      0.00         3\n",
      "Premature ventricular contraction       0.00      0.00      0.00         6\n",
      "\n",
      "                         accuracy                           0.98       433\n",
      "                        macro avg       0.33      0.33      0.33       433\n",
      "                     weighted avg       0.96      0.98      0.97       433\n",
      "\n",
      "\n",
      "True Positives (TP): [424   0   0]\n",
      "False Positives (FP): [9 0 0]\n",
      "False Negatives (FN): [0 3 6]\n",
      "True Negatives (TN): [  0 430 427]\n",
      "Sensitivity (TPR): [1. 0. 0.]\n",
      "Precision (PPV): [0.97921478        nan        nan]\n",
      "Accuracy (ACC): [0.97921478 0.99307159 0.98614319]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jgjlsdxn2hd3fg2yfrd791gh0000gn/T/ipykernel_10050/2035090956.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  PPV = TP / (TP + FP)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(feature_matrix111)\n",
    "X_test_scaled = scaler.transform(feature_matrix109)\n",
    "\n",
    "# SVM training with patient 111's data\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train_scaled, labels111)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(labels109, y_pred)\n",
    "\n",
    "# Generate the classification report for patient 109's data\n",
    "classification_rep_109 = classification_report(labels109, y_pred, labels=np.unique(labels109), target_names=[annotation_classes_map.get(label, 'Other') for label in np.unique(labels109)], zero_division=0)\n",
    "\n",
    "print(f'Accuracy for patient 109: {accuracy}')\n",
    "print(classification_rep_109)\n",
    "\n",
    "cm = confusion_matrix(labels109, y_pred, labels=np.unique(labels109))\n",
    "print()\n",
    "\n",
    "# Calculate additional metrics from the confusion matrix if needed\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"Sensitivity (TPR): {TPR}\")\n",
    "print(f\"Precision (PPV): {PPV}\")\n",
    "print(f\"Accuracy (ACC): {ACC}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
